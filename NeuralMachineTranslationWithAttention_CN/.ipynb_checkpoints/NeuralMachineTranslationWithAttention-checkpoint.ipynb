{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "#!pip install -q tensorflow-gpu == 2.0.0-beta1\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "#path_to_zip = tf.keras.utils.get_file(\n",
    "#    'cmn-eng.zip', origin = 'http://storage.googleapis.com/download.tensorflow.org/data/cmn-eng.zip', extract = True)\n",
    "\n",
    "path_to_file = '/home/sixianzhang/Documents/Data/cmn-eng/cmn.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    \n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([\\u4e00-\\u9fa5？。！，?.!,])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5？。！，?.!,]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding = 'UTF-8').read().strip().split('\\n')\n",
    "    \n",
    "    #print(lines[-5:num_examples])\n",
    "            \n",
    "    #print([[w for w in l.split('\\t')] for l in lines[:num_examples]])\n",
    "        \n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    \n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if a person has not had a chance to acquire his target language by the time he s an adult , he s unlikely to be able to reach native speaker level in that language . <end>\n",
      "<start> 如 果 一 個 人 在 成 人 前 沒 有 機 會 習 得 目 標 語 言 ， 他 對 該 語 言 的 認 識 達 到 母 語 者 程 度 的 機 會 是 相 當 小 的 。 <end>\n"
     ]
    }
   ],
   "source": [
    "en, sp = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(sp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        filters = '')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    \n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, \n",
    "                                                         padding = 'post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples = None):\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "    \n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "    \n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 10000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 8000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size = 0.2)\n",
    "\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!= 0:\n",
    "            print(\"%d -------> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 -------> <start>\n",
      "55 -------> 没\n",
      "15 -------> 有\n",
      "25 -------> 人\n",
      "42 -------> 喜\n",
      "77 -------> 欢\n",
      "756 -------> 战\n",
      "845 -------> 争\n",
      "3 -------> 。\n",
      "2 -------> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 -------> <start>\n",
      "266 -------> nobody\n",
      "172 -------> likes\n",
      "632 -------> war\n",
      "3 -------> .\n",
      "2 -------> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF dataset\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 16\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 256\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2547, 3406)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_inp_size, vocab_tar_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([16, 22]), TensorShape([16, 13]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units,batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                      return_sequences = True, \n",
    "                                      return_state = True,\n",
    "                                      recurrent_initializer = 'glorot_uniform')\n",
    "    \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "    \n",
    "    def initialization_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (16, 22, 256)\n",
      "Encoder Hidden state shape: (batch size, units) (16, 256)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_hidden = encoder.initialization_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        \n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(score, axis = 1)\n",
    "        \n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (16, 256)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (16, 22, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units, \n",
    "                                      return_sequences = True,\n",
    "                                      return_state = True,\n",
    "                                      recurrent_initializer = 'glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "    \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        \n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = -1)\n",
    "        \n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (16, 3406)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _ , _ = decoder(tf.random.uniform((BATCH_SIZE,1)), sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits = True, reduction = 'none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype = loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer = optimizer, \n",
    "                                encoder = encoder, \n",
    "                                decoder = decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        \n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        \n",
    "        # Teacher Forcing\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            \n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            \n",
    "            dec_input = tf.expand_dims(targ[:,t], 1)\n",
    "        \n",
    "    batch_loss = (loss/ int(targ.shape[1]))\n",
    "    \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    \n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.5303\n",
      "Epoch 1 Batch 100 Loss 0.4662\n",
      "Epoch 1 Batch 200 Loss 0.8814\n",
      "Epoch 1 Batch 300 Loss 0.9283\n",
      "Epoch 1 Batch 400 Loss 0.6199\n",
      "Epoch 1 Loss 0.6086\n",
      "Time taken for 1 epoch 56.46624946594238 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.4022\n",
      "Epoch 2 Batch 100 Loss 0.3688\n",
      "Epoch 2 Batch 200 Loss 0.6536\n",
      "Epoch 2 Batch 300 Loss 0.7188\n",
      "Epoch 2 Batch 400 Loss 0.4862\n",
      "Epoch 2 Loss 0.4493\n",
      "Time taken for 1 epoch 30.553716897964478 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.3159\n",
      "Epoch 3 Batch 100 Loss 0.2866\n",
      "Epoch 3 Batch 200 Loss 0.5072\n",
      "Epoch 3 Batch 300 Loss 0.5072\n",
      "Epoch 3 Batch 400 Loss 0.3887\n",
      "Epoch 3 Loss 0.3387\n",
      "Time taken for 1 epoch 30.646708726882935 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.2197\n",
      "Epoch 4 Batch 100 Loss 0.2229\n",
      "Epoch 4 Batch 200 Loss 0.3870\n",
      "Epoch 4 Batch 300 Loss 0.3787\n",
      "Epoch 4 Batch 400 Loss 0.3059\n",
      "Epoch 4 Loss 0.2631\n",
      "Time taken for 1 epoch 30.863205432891846 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1571\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " [_Derived_]  Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size]: [1, 512, 256, 1, 1, 16] \n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\n\t [[StatefulPartitionedCall_1]]\n\t [[Adam/Adam/update_4/mul_1/_150]] [Op:__inference_train_step_29710]\n\nFunction call stack:\ntrain_step -> train_step -> train_step\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-68e6b88e4089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    402\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \"\"\"\n\u001b[1;32m    588\u001b[0m     return self._call_flat(\n\u001b[0;32m--> 589\u001b[0;31m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0m\u001b[1;32m    590\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m    591\u001b[0m                            resource_variable_ops.ResourceVariable))))\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m:  [_Derived_]  Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size]: [1, 512, 256, 1, 1, 16] \n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\n\t [[StatefulPartitionedCall_1]]\n\t [[Adam/Adam/update_4/mul_1/_150]] [Op:__inference_train_step_29710]\n\nFunction call stack:\ntrain_step -> train_step -> train_step\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    start = time.time()\n",
    "    \n",
    "    enc_hidden = encoder.initialization_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "\n",
    "    if (epoch + 1) % 2  == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f232c6f1f28>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 很 晚 了 <end>\n",
      "Predicted translation: it s very hungry . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 24456 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 26202 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:176: RuntimeWarning: Glyph 24456 missing from current font.\n",
      "  font.load_char(ord(s), flags=flags)\n",
      "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:176: RuntimeWarning: Glyph 26202 missing from current font.\n",
      "  font.load_char(ord(s), flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'很晚了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'esta es mi vida.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'¿todavia estan en casa?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'adiós.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "translate(u'trata de averiguarlo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(u'hola.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
